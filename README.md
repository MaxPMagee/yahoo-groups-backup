# yahoo-groups-backup
A python script to backup the contents of Yahoo! groups, be they private or public.

## Setup/Requirements

The project requires Python 3, Mongo, and a computer with a GUI as Selenium is used for the scraping (to be able to handle private groups).

[virtualenv](https://virtualenv.pypa.io/en/stable/) is recommended.

    git clone https://github.com/csaftoiu/yahoo-groups-backup.git
    cd yahoo-groups-backup
    pip install -r requirements.txt

## Example

To scrape an entire site, say the `concatenative` group:

    ./yahoo-groups-backup.py scrape_messages concatenative

This will shove all the messages into a Mongo database (default `localhost:27017`), into the database of the same name as the group.

To scrape the files as well (though this group has no files):

    ./yahoo-groups-backup.py scrape_files concatenative

To dump the site as a human-friendly, fully static (i.e. viewable from the file system) website:

    ./yahoo-groups-backup.py dump_site concatenative concatenative_static_site

Then simply open `concatenative_static_site/index.html` and browse!

## Full Usage

To see the full usage:

    ./yahoo-groups-backup.py -h

## Development Approach

Please read this thoroughly before modifying the code. It lists some
gotchas which may be helpful to know ahead of time.

### Scraping - Messages

Scraping is done with Selenium to allow for scraping private sites. 

The Yahoo Groups undocumented JSON API is used:

* `https://groups.yahoo.com/api/v1/groups/<group_name>/messages?count=1&sortOrder=desc&direction=-1`
to get the total number of messages.
* `https://groups.yahoo.com/api/v1/groups/<group_name>/messages/<message_number>` to 
get the data, with HTML content, for the given message
* `https://groups.yahoo.com/api/v1/groups/<group_name>/messages/<message_number>/raw` to 
get the data, with raw content, for the given message

All the message data from the API is combined and inserted into a mongo
database with the same name as the group. Data is stored as returned
from the API except the message id is stored into the `_id` field.
 
### Scraping - Files

Files are scraped through the human-consumable interface (i.e. the website) 
as I couldn't figure out the JSON API calls for it. 

They are stored in a GridFS instance with the name `<group_name>_gridfs`.

### Static Site Dumping

All the group data - messages and files - can be dumped into a static
site which is viewable without any internet connection whatsoever, and
without needing to run a local browser.

The static site is an AngularJS app. The message index data is
stored as a separate .js file and loaded with JSONP. This allows us 
to essentially load data from the local filesystem.

The messages themselves are stored in batches of `n` messages (default 500) and 
loaded on-demand. 

A site is "dumped" by copying everything but the data from the
`static_site_template` directory, and rendering the necessary data into
jsonp files.

The group files are copied into the `files` directory, and it is left
up to the browser to display the contents, as if browsing any other
local directory.

#### Angular Templates

Angular Templates are in the `modules` subdirectory. The tricky part is
that there is no way to load these `.html` files if the page is being
served from the file-system. Modern browsers prevent access to 
arbitrary files due to security concerns, and they won't load the
`<script type="text/ng-template" ...>` tags.

To work around this without being forced to include all the `.html`
in one file, there's the `modules/load-templates.js` file. This
preloads all the templates into `$templateCache`. This file is
automatically generated by `dump_site`, which reads the 
`modules/*.html` files and inserts their data into the file. 

**NOTE:** Template ids all start with `./`, e.g. `modules/foo.html`
will be loaded as the template called `./modules/foo.html`. If you
include a template without a leading `.`, it will not work on the
generated site.

Paths are not followed recursively.
